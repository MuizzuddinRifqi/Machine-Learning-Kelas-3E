{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 1\n",
        "Klasifikasi üê± dan üê∂"
      ],
      "metadata": {
        "id": "OBtSxEv-x-2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deskripsi\n",
        "Pada praktikum ini kita akan membuat model klasifikasi CNN sederhana pada kasus citra kucing dan anjing."
      ],
      "metadata": {
        "id": "GDCc67_hyCuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nYn-7tH0RAI",
        "outputId": "185c6b56-d081-482a-dcf6-9adec58b0aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  # menggunakan tensorflow untuk berbagai fungsi dan objek yang disediakan\n",
        "from keras.preprocessing.image import ImageDataGenerator  # buat variasi data latihan dengan mengubah citra asli secara acak, seperti rotasi, pergeseran, pemotongan, dan lainnya"
      ],
      "metadata": {
        "id": "9PQUpwEH0xmR"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentasi data gambar pada data latihan.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # normalisasi rentang nilai piksel gambar menjadi 0-1 dengan membagi setiap piksel dengan 255.\n",
        "    shear_range=0.2,  # ubah sudut citra secara acak dengan rentang 0,2.\n",
        "    zoom_range=0.2,  # perbesar atau perkecil citra secara acak dengan faktor 0,2.\n",
        "    horizontal_flip=True  # secara acak balik citra secara horizontal.\n",
        ")\n",
        "\n",
        "# hasilkan batch data latihan secara acak dari direktori yang ditentukan.\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataml/dataset/training_set',  # direktori yang berisi data latihan.\n",
        "    target_size=(64, 64),  # ubah semua gambar menjadi ukuran 64x64 piksel.\n",
        "    batch_size=32,  # jumlah sampel gambar dalam setiap batch data latihan.\n",
        "    class_mode='binary'  # mode untuk klasifikasi biner.\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMXuRvZZ1b7I",
        "outputId": "827e12f8-0389-47e7-b433-81ddbbd9082f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalisasi data gambar pada data pengujian.\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255  # ubah rentang nilai piksel gambar menjadi 0-1 dengan membagi setiap piksel dengan 255, ini normalisasi data gambar.\n",
        ")\n",
        "\n",
        "# hasilkan batch data pengujian secara acak dari direktori yang diberikan.\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataml/dataset/test_set',  # lokasi direktori yang berisi data pengujian.\n",
        "    target_size=(64, 64),  # ubah semua gambar menjadi ukuran 64x64 piksel.\n",
        "    batch_size=32,  # jumlah sampel gambar dalam setiap batch data pengujian.\n",
        "    class_mode='binary'  # mode untuk klasifikasi biner.\n",
        ")\n"
      ],
      "metadata": {
        "id": "Tv-ATP9314UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dadcf9c-5d48-41fb-ef42-095b85e755a4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# buat model berurutan dan simpan dalam variabel cnn.\n",
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "-x9mCy6i2C5I"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tambahkan lapisan konvolusi (Conv2D) ke model Sequential (cnn).\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "yHvKbuw_2GXz"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tambahkan lapisan pooling maksimum (MaxPool2D) ke dalam model Sequential (cnn)\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "qbnWMjzJ2Kjd"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))  # menggunakan 32 filter dengan kernel berukuran 3x3 dan fungsi aktivasi ReLU\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))  # melakukan max pooling dengan jendela berukuran 2x2 dan langkah (stride) 2"
      ],
      "metadata": {
        "id": "p-bVMRQ52No7"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())  # melakukan proses flatten untuk mengubah data menjadi satu dimensi"
      ],
      "metadata": {
        "id": "sDoVgC222QEN"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))  # mentambahkan lapisan dengan 128 unit dan fungsi aktivasi ReLU"
      ],
      "metadata": {
        "id": "2nV2BXf62SMx"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  # mentambahkan lapisan dengan 1 unit dan fungsi aktivasi sigmoid"
      ],
      "metadata": {
        "id": "JN4nBFjM2URN"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # menggunakan optimizer 'adam', loss function 'binary_crossentropy', dan metrik evaluasi 'accuracy'\n"
      ],
      "metadata": {
        "id": "baa7Xc6R2V-Z"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "id": "DTSz8If_r8zD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375eb477-39db-409b-97c8-42ba2e7271f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "251/251 [==============================] - 2577s 10s/step - loss: 0.6763 - accuracy: 0.5798 - val_loss: 0.6349 - val_accuracy: 0.6480\n",
            "Epoch 2/25\n",
            "251/251 [==============================] - 43s 171ms/step - loss: 0.6137 - accuracy: 0.6667 - val_loss: 0.5961 - val_accuracy: 0.6735\n",
            "Epoch 3/25\n",
            "251/251 [==============================] - 38s 153ms/step - loss: 0.5704 - accuracy: 0.7007 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
            "Epoch 4/25\n",
            "251/251 [==============================] - 38s 151ms/step - loss: 0.5342 - accuracy: 0.7328 - val_loss: 0.5179 - val_accuracy: 0.7565\n",
            "Epoch 5/25\n",
            "251/251 [==============================] - 39s 154ms/step - loss: 0.5088 - accuracy: 0.7521 - val_loss: 0.4914 - val_accuracy: 0.7680\n",
            "Epoch 6/25\n",
            "251/251 [==============================] - 39s 154ms/step - loss: 0.4831 - accuracy: 0.7647 - val_loss: 0.4736 - val_accuracy: 0.7855\n",
            "Epoch 7/25\n",
            "251/251 [==============================] - 38s 150ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4953 - val_accuracy: 0.7750\n",
            "Epoch 8/25\n",
            "251/251 [==============================] - 43s 171ms/step - loss: 0.4529 - accuracy: 0.7841 - val_loss: 0.4666 - val_accuracy: 0.7950\n",
            "Epoch 9/25\n",
            "251/251 [==============================] - 38s 151ms/step - loss: 0.4277 - accuracy: 0.8017 - val_loss: 0.4543 - val_accuracy: 0.8010\n",
            "Epoch 10/25\n",
            "251/251 [==============================] - 38s 153ms/step - loss: 0.4174 - accuracy: 0.8071 - val_loss: 0.5037 - val_accuracy: 0.7705\n",
            "Epoch 11/25\n",
            "251/251 [==============================] - 38s 152ms/step - loss: 0.3965 - accuracy: 0.8212 - val_loss: 0.4823 - val_accuracy: 0.7960\n",
            "Epoch 12/25\n",
            "251/251 [==============================] - 39s 156ms/step - loss: 0.3856 - accuracy: 0.8189 - val_loss: 0.4452 - val_accuracy: 0.8055\n",
            "Epoch 13/25\n",
            "251/251 [==============================] - 38s 151ms/step - loss: 0.3638 - accuracy: 0.8355 - val_loss: 0.4626 - val_accuracy: 0.7935\n",
            "Epoch 14/25\n",
            "251/251 [==============================] - 38s 150ms/step - loss: 0.3516 - accuracy: 0.8427 - val_loss: 0.4947 - val_accuracy: 0.7955\n",
            "Epoch 15/25\n",
            "251/251 [==============================] - 38s 153ms/step - loss: 0.3444 - accuracy: 0.8442 - val_loss: 0.4657 - val_accuracy: 0.8040\n",
            "Epoch 16/25\n",
            "251/251 [==============================] - 43s 171ms/step - loss: 0.3248 - accuracy: 0.8543 - val_loss: 0.4591 - val_accuracy: 0.8035\n",
            "Epoch 17/25\n",
            "251/251 [==============================] - 43s 173ms/step - loss: 0.3094 - accuracy: 0.8624 - val_loss: 0.5117 - val_accuracy: 0.7900\n",
            "Epoch 18/25\n",
            "251/251 [==============================] - 40s 158ms/step - loss: 0.3021 - accuracy: 0.8653 - val_loss: 0.4933 - val_accuracy: 0.8035\n",
            "Epoch 19/25\n",
            "251/251 [==============================] - 38s 152ms/step - loss: 0.2837 - accuracy: 0.8825 - val_loss: 0.5370 - val_accuracy: 0.7855\n",
            "Epoch 20/25\n",
            "251/251 [==============================] - 40s 158ms/step - loss: 0.2700 - accuracy: 0.8859 - val_loss: 0.5076 - val_accuracy: 0.8025\n",
            "Epoch 21/25\n",
            "251/251 [==============================] - 40s 157ms/step - loss: 0.2623 - accuracy: 0.8911 - val_loss: 0.5080 - val_accuracy: 0.8095\n",
            "Epoch 22/25\n",
            "251/251 [==============================] - 43s 173ms/step - loss: 0.2583 - accuracy: 0.8954 - val_loss: 0.5013 - val_accuracy: 0.8095\n",
            "Epoch 23/25\n",
            "251/251 [==============================] - 39s 156ms/step - loss: 0.2352 - accuracy: 0.9024 - val_loss: 0.5505 - val_accuracy: 0.8040\n",
            "Epoch 24/25\n",
            "251/251 [==============================] - 38s 153ms/step - loss: 0.2270 - accuracy: 0.9035 - val_loss: 0.6217 - val_accuracy: 0.7945\n",
            "Epoch 25/25\n",
            "251/251 [==============================] - 39s 157ms/step - loss: 0.2132 - accuracy: 0.9092 - val_loss: 0.6110 - val_accuracy: 0.8025\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7837a6086320>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Langkah 5 - Prediksi dengan 1 Citra**"
      ],
      "metadata": {
        "id": "PPlvMRmYr9me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/Machine Learning/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "id": "gQOLF07FsAwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe30b07b-67c2-4bfe-b538-2d775b9ea7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 163ms/step\n"
          ]
        }
      ]
    }
  ]
}