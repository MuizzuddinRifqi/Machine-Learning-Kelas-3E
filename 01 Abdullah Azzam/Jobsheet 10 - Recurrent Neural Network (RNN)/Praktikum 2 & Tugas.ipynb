{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV73UEG1QEv0"
      },
      "source": [
        "## **Praktikum 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ox-IKJ9Ag4a"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WEJjrye1AUYq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylNE_71DAlO5"
      },
      "source": [
        "# Download Dataset Shakespeare\n",
        "Sesuaikan dengan lokasi data yang Anda punya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSji8fv8Afdd",
        "outputId": "441ffef1-e6b7-4bf9-8568-45313363d47e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7j3ZNoSBVXh"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEadThoZAm3I",
        "outputId": "4f3f0d14-293d-46f9-fd00-2a071ec4edcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KED738anBrST",
        "outputId": "4e30be30-7c80-4824-f043-d2b2dc4159da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_2v7FRTBsk3",
        "outputId": "490039e5-fb40-4733-857a-4aa7ee97efbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOL_ZPqyBxpJ"
      },
      "source": [
        "## Olah Teks\n",
        "\n",
        "## Vectorize Teks\n",
        "\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz1KMCP5Bvqb",
        "outputId": "79ee7fcb-25c7-4c23-9bff-d10f3fd4b9d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3yfkY_bB3jh"
      },
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4mRN7ZHKB1-m"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziUqW2tgB6vi"
      },
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP_LuMxBB5Mh",
        "outputId": "b4e0310f-f7ae-48bb-c95e-84d241b37194"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDjNCYEfB9_J"
      },
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "75rnpfDjB8h4"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9ZyOyfWGx27"
      },
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ6Pq_KZB_Uz",
        "outputId": "25bb2918-3c03-44e1-d76d-61fc4e9d252d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6kKfs34QEv5"
      },
      "source": [
        "Anda dapat menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wksEj8q8G9MY",
        "outputId": "746f4bab-04ea-4476-b859-970df11551c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7LQtbIWfG-O9"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmFP37MhHFsT"
      },
      "source": [
        "## Prediksi\n",
        "\n",
        "## Membuat Training Set dan Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmn56mqGG_Di",
        "outputId": "76bfb6ad-5f58-4c34-83d0-a9801c938ea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3SGr01hrHPII"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcE8fcBEHRsx",
        "outputId": "9dc2c31a-15f6-48a6-df68-4f77d159c98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "twJQtoK-HTG0"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DFYu4WSHisN"
      },
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-SGN4x4HUXA",
        "outputId": "c565d38e-1fae-4bc0-d624-2fa37c6663dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNKJ1WAzHlNj"
      },
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccBoc9zMHjuY",
        "outputId": "56980a70-90e7-4f82-bf82-b0bc8e584bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etZbs7DBHn87"
      },
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qH1C6Pg1HmYA"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6ZNRkQcHo-B",
        "outputId": "e1285b32-c692-402e-8579-365bece07f11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lBOt_zpPHqMY"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBfUnKyzHrMi",
        "outputId": "b21a9969-fe73-48d6-c204-7bb2204f8100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkV_JOoSH1xj"
      },
      "source": [
        "## Membuat Batch Training\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU1HwOEMHsE0",
        "outputId": "68e8c471-1482-4493-b9c2-cdfd16c4379b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJd6WK1tH42D"
      },
      "source": [
        "## Buat Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eFdiB0sMH3jx"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hGi5QQRAH6mz"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "54I4vDGZIHWQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI_qQeuuIKJz"
      },
      "source": [
        "## Uji Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ShpYRhaIIhb",
        "outputId": "9c1a8ece-055d-4417-81fc-f6b9c59ec671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9OvE0BwIMRi",
        "outputId": "3c156013-733f-44cb-c5b6-1830640b88cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "zPyQg3QoITLU"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rMD8C_7IU_7",
        "outputId": "68c7bce9-6eea-483d-91c1-bd07e5513ce0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([32, 11, 18, 48, 13, 21, 31, 60, 21, 14, 41, 65, 59, 12, 44, 35, 23,\n",
              "        9, 24, 49, 44, 36, 21, 26, 53, 43, 41, 60, 53, 34, 39, 16, 33, 53,\n",
              "       40, 14,  8, 20, 48, 54, 15, 20, 13, 63,  6, 30, 65,  0, 39, 33, 34,\n",
              "        4, 48, 13, 37, 63, 30, 27, 55, 43,  5, 43, 15,  1,  5, 38, 20, 63,\n",
              "       10, 12, 37, 49, 41, 38, 36,  3,  3,  8, 58,  3, 53, 47,  0, 59, 65,\n",
              "        5, 17,  4, 33, 50, 27,  9, 63, 45, 40, 42, 44, 40, 54, 49])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwHMAy3rIV2y",
        "outputId": "72829b18-f8f3-4378-de85-5cf52d78bb9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'husband, he is gone to save far off,\\nWhilst others come to make him lose at home:\\nHere am I left to '\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"S:Ei?HRuHAbzt;eVJ.KjeWHMndbunUZCTnaA-GioBG?x'Qz[UNK]ZTU$i?XxQNpd&dB\\n&YGx3;XjbYW!!-s!nh[UNK]tz&D$TkN.xfaceaoj\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1EvBjdeIYvc"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "## Tambahan optimizer dan fungsi loss\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Y-F1eYapIXa7"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL922-A5Ia5x",
        "outputId": "0080839e-1832-4202-f7de-bdc8d4e29e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1893644, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noKzdo82Idys"
      },
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmNIoC3pIb2q",
        "outputId": "2f30e01f-fac9-47fe-c867-2ce5fc1538a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65.98084"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgYuhXwhJ5rE"
      },
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "G_udKB2DJ3gJ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnRE78KZMsA_"
      },
      "source": [
        "## Konfigurasi Checkpoints\n",
        "\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "IU9V75KHMq9c"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BJY-DsxMu8W"
      },
      "source": [
        "## Lakukan Proses Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3YGIJEgBMt9v"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL-hiZMkMwit",
        "outputId": "5714002b-a1d0-466d-df9c-4400d60fc00c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 18s 70ms/step - loss: 2.7284\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 14s 61ms/step - loss: 1.9943\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 13s 60ms/step - loss: 1.7133\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.5525\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.4526\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 1.3841\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.3318\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.2867\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.2449\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.2046\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCEBH8Vt1a1g"
      },
      "source": [
        "## Generate Teks\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VMJBY1EdMxth"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-YjempKv1c9Z"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d89xI-Y1eAR",
        "outputId": "d1f7fbe7-3538-4557-e49e-50747dadf4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "And, brot your honour!\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Herraim' most burthen'd by this of your course,\n",
            "Sounds that thou couldst become, when he lives some world,\n",
            "To know us think him feeling in the field\n",
            "Coil's the fruit that Edward stars! Come on,\n",
            "And when you are like the dutual should\n",
            "Look himself, as bright. My lord's depostion,\n",
            "With all the sacraments feignristery deward,\n",
            "The statu, my gracious upubs and throwness\n",
            "What might hath held me asks!\n",
            "With Clifford slaughter that calls fight's death:\n",
            "Therefore; he is a rodain proclamation.\n",
            "3 KING HENRY VI:\n",
            "Son, boy.' is not yet ruthless the youth poor: stay thy grace\n",
            "For thy\n",
            "Herein I owe; for how you at her bread,\n",
            "Whose torthers by sight Juliet,\n",
            "To lay us had no sickly needer.\n",
            "Nothona,, sir, but I wake it nobly.\n",
            "How is it by me? defends nothing steal what my father gate!\n",
            "\n",
            "FLORIZEL:\n",
            "Go, I know.\n",
            "\n",
            "ANGELO:\n",
            "Or my goodness are gone: undin profess? Go who be found.\n",
            "\n",
            "JULIET:\n",
            "Go, sir. Where is it meet my wife is we?\n",
            "The courge, our countrymen: now jot advised  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.2170767784118652\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF9yBIjG1gul",
        "outputId": "f2f1732d-81a0-4ea9-f8db-a949544b69d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nI must reyeme:\\nLo, comes this time to whom I lay her swift,\\nReceive she shall speak of smile, I have fought\\nFor sending ragss retry's other of his pire.\\n\\nKING RICHARD III:\\nDraw thee, fellow, I am true to prison.\\n\\nKING RICHARD III:\\nCome, cousin!\\n\\nFirst Lord:\\nThe groses see what he straight as sure thee hence and,\\nTranio's boarery to ensue him shades like her;\\nFor I am not often so, unfitly a silky wash,\\nBut if you some courteous spain himself as muciness.\\n\\nNORTHLOHS:\\nGo, sir, I love thy whose malice, with him!\\n\\nMOPSAA:\\nYou love them mine.\\n\\nCORIOLANUS:\\nBut he's not enough: what\\nmorsion then let this is various blocks.\\n\\nESCALUS:\\nI grow this sirma was ot scroat;\\nHea'tile men is so look, and\\nSo strikes and timely dear. my lord, my moody blood\\nEre thou in the clamories what of willish by this reason:\\nThat is't, so, both your honour I\\nIn this time is his death unbeing breath.\\nHere see him till thee forward?\\n\\nClown:\\nPetrut him effemine this resort were true prince,\\nAitinusion, friends, sir; b\"\n",
            " b\"ROMEO:\\nShe that this good liege:\\nYour surmoss'd and aside you out.\\n\\nWhith brine Hanging?\\nApomel of him and God and brother do dree the\\nlaw, I must go burner, to Hetry rage,\\nAnd feather years and roar into Venice:\\nWhy hold an instantire of eyes or to?\\n\\nFirst Conspirator:\\nIf you needful very glow,\\nThey shall be early take his rubbia to very\\nmaliciatest, 'twere this is felour more.\\nHere in this revolt; yet wholesome\\nHere stronger in thine. Camillo, we'll stir.\\n\\nLord:\\nCousin, cousin; but, O, let me have your causes to be\\nDisperution, and unphostry gainsa's deed,\\nAnd foul mudder with us when she chearers,\\nBe find of all the swords ride fily and entrance.\\nBut he'r the Lord ENwLOSk:\\nAwhile, piercing parts I was worn banish'd\\nAs what I must needs be found.\\n\\nEXETER:\\nCominius, what though althoutiful of by mother?\\n\\nMENENIUS:\\nWhat's the shubbs thy sovereign leost?\\nNow, conspure thy wife, Pompey and pray,\\nOut of a worthily, thou didst not hear there!\\n\\nISABELLA:\\nAnd would so impuals groal.\\n\\nCARISBELL:\\nMi\"\n",
            " b\"ROMEO:\\nGremio you between thee, sir; he hath done woo her,\\nLet's hear before advertister.\\n\\nLUCIO:\\n\\nDUKE OF YORK:\\nWhy, that it straight for virtue she what he\\nwould act a royal serviction!\\nCome, cousin, friar, what new breath with music in worshir;\\nOne, royal harlous cares. My, should not news.\\nYou must and bulds; and once a tembling delight.\\n\\nMIRANDA:\\nFindly that you joy, 'tis in me\\ninvellabons have enough, tell me, cousin with the pretty\\nThat thou stuck'd by can not abread him in this cape.\\n\\nLADY CRINCENTIO:\\nThere's not the duke, sir?\\n\\nMusiders:\\nHeavens, and your figly pierce was seen in me\\nThe occasion they are. The wnoth o'er soft certain a carcomed\\nWith a little silkness in a life,\\nThat would have known my headful suffer'\\nA thousand vinter's sires\\nAnd sent me to the life.\\n\\nHENRY BOLINGBROKE:\\nShe's an ere more grave blame.\\n\\nSecond Senator:\\n'Twas me, in mouth, our cousin Heavens!\\nMake haste thee not the children's quarrello?\\n\\nServant:\\nKnows some hope to have to make no learness:\\nMore towar\"\n",
            " b\"ROMEO:\\nO protery, thence fear either were not?\\n\\nKING RICHARD III:\\nUpon my souls, when thou gentleman meet, Sir Wilor:\\nO exham I think it were a prince; but if you must\\nwith tear through with him, good with a right.\\n\\nLADY CAPULET:\\n\\nPROSPERO:\\nMore ligets us, that gives it at your course!\\nFor more rather betward away,\\nGow'd this the wars! and wether he\\nExtoned us good lord of my mothers:\\nFor God's name deep to fails, present,\\nIs now run an everlory,\\nOur horses.\\n\\nCAMILLO:\\nHe was wife with a lightly some of these debling,\\nAnd git that thought upon my master and\\nRoman from the case of my guiltless commiss\\nAhe will us; but I foal, my lord:\\nIf you. You undoke gone!\\n\\nTRANIO:\\nCan we to him that bear by me?\\n\\nMIRANDA:\\nO, when, I come\\nTo merit be for the firlions.\\nBut lest the champ wheth an exvise\\nTo right news from quatispy in one of his siste,\\nRepail York impertise Prieceas me free up his due-bet,\\nAnd playned by his same, fear me, their loaths\\nThat you cut off the dire, ore, oble controll'd,\\nAnd that \"\n",
            " b\"ROMEO:\\nVodsay! proce protest un receives a king,\\nAnd being the writone, get thee join'd to the might,\\nOr sometimes moded come hither in a half-brown.\\nYou are exellood?\\n\\nCORIOLANUS:\\nWhy, But here wine, and what my counch?\\n\\nBAANTIS:\\nSir Palkin. What death they both truth of yours? Tyat counsell\\nOf Partain when he was never seemed\\nMy bark'd and all thee to a teft of wises.\\nAnd I answered never but fare look on,\\nWhereof are they comes to the marriage, of our king:\\n'Two, my gracious lords rootes me with\\nAnsined Claudio's, who,\\nI must confess with Hereford.\\n\\nKING RICHARD II:\\nWhat to my very hour I will? may leave,\\nAnd yet repegation of breathers to our from the city\\nBut that the King of sorrow better blood.\\nYou're woo you, look them all truits; 'tis every day in\\nAmpleisedy and thy prithee, live;\\nProclaim it change thee to a motter glass,\\nAnd thought is the father of thy knee.\\nHere's no more unto a gosses; any,\\nLike officer of our crown in France,\\nAnd now foul delight there:\\nDirest God promise the \"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw6gxAF01kzx"
      },
      "source": [
        "## Ekspor Model Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvrIalgz1nor",
        "outputId": "099643cb-bb20-4a69-81ed-84ef805398fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7ad5cc688d30>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAl8oqye1pL1",
        "outputId": "09da0a27-3aa2-4c46-b5d5-d0e44835c9b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Thou hast made-dealth some spirt in his windst now\n",
            "fence and golden then mean'd measure he doth the\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYLvsvEcsYe5"
      },
      "source": [
        "## **Tugas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "y_m6HDuqsaih"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "PUVBQzW7sdjT"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "PXyM7QYrslU3"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNnkc-xHsm39",
        "outputId": "c3d972df-25cc-491e-a0f3-1fbd2e56c08f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 14s 61ms/step - loss: 2.7293\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ad55df90b50>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpnaXIx0soZv",
        "outputId": "2113a880-c2bc-4a42-f3a5-ab07590a0f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.2046\n",
            "Epoch 1 Batch 50 Loss 2.0834\n",
            "Epoch 1 Batch 100 Loss 1.9616\n",
            "Epoch 1 Batch 150 Loss 1.9120\n",
            "\n",
            "Epoch 1 Loss: 1.9974\n",
            "Time taken for 1 epoch 13.05 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8495\n",
            "Epoch 2 Batch 50 Loss 1.7606\n",
            "Epoch 2 Batch 100 Loss 1.6718\n",
            "Epoch 2 Batch 150 Loss 1.6780\n",
            "\n",
            "Epoch 2 Loss: 1.7168\n",
            "Time taken for 1 epoch 14.04 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5715\n",
            "Epoch 3 Batch 50 Loss 1.5603\n",
            "Epoch 3 Batch 100 Loss 1.5226\n",
            "Epoch 3 Batch 150 Loss 1.4814\n",
            "\n",
            "Epoch 3 Loss: 1.5558\n",
            "Time taken for 1 epoch 11.98 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4846\n",
            "Epoch 4 Batch 50 Loss 1.4915\n",
            "Epoch 4 Batch 100 Loss 1.4420\n",
            "Epoch 4 Batch 150 Loss 1.4280\n",
            "\n",
            "Epoch 4 Loss: 1.4565\n",
            "Time taken for 1 epoch 12.16 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3909\n",
            "Epoch 5 Batch 50 Loss 1.3703\n",
            "Epoch 5 Batch 100 Loss 1.3780\n",
            "Epoch 5 Batch 150 Loss 1.3633\n",
            "\n",
            "Epoch 5 Loss: 1.3867\n",
            "Time taken for 1 epoch 12.28 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.2789\n",
            "Epoch 6 Batch 50 Loss 1.3129\n",
            "Epoch 6 Batch 100 Loss 1.3377\n",
            "Epoch 6 Batch 150 Loss 1.3191\n",
            "\n",
            "Epoch 6 Loss: 1.3339\n",
            "Time taken for 1 epoch 12.28 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2579\n",
            "Epoch 7 Batch 50 Loss 1.3144\n",
            "Epoch 7 Batch 100 Loss 1.3190\n",
            "Epoch 7 Batch 150 Loss 1.2891\n",
            "\n",
            "Epoch 7 Loss: 1.2889\n",
            "Time taken for 1 epoch 13.00 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2280\n",
            "Epoch 8 Batch 50 Loss 1.2530\n",
            "Epoch 8 Batch 100 Loss 1.2913\n",
            "Epoch 8 Batch 150 Loss 1.2817\n",
            "\n",
            "Epoch 8 Loss: 1.2474\n",
            "Time taken for 1 epoch 13.00 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1995\n",
            "Epoch 9 Batch 50 Loss 1.1693\n",
            "Epoch 9 Batch 100 Loss 1.2054\n",
            "Epoch 9 Batch 150 Loss 1.2367\n",
            "\n",
            "Epoch 9 Loss: 1.2083\n",
            "Time taken for 1 epoch 12.72 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1057\n",
            "Epoch 10 Batch 50 Loss 1.1879\n",
            "Epoch 10 Batch 100 Loss 1.1629\n",
            "Epoch 10 Batch 150 Loss 1.1988\n",
            "\n",
            "Epoch 10 Loss: 1.1678\n",
            "Time taken for 1 epoch 12.23 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  mean.reset_states()\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    logs = model.train_step([inp, target])\n",
        "    mean.update_state(logs['loss'])\n",
        "\n",
        "    if batch_n % 50 == 0:\n",
        "      template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "      print(template)\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print()\n",
        "  print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "  print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dRCx3ssss-G"
      },
      "source": [
        "## **SOAL**\n",
        "\n",
        "Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu1BR7oXsudz"
      },
      "source": [
        "JAWAB :\n",
        "\n",
        "Perbedaannya terdapat pada prosedur pelatihan. Yang dimana pendekatan pelatihan yang digunakan pada praktikum 2 lebih sederhana dan umum, yaitu menggunakan metode 'model.fit'. Dan pada kode tugas menggambarkan pendekatan pelatihan yang lebih spesifik dan kompleks, yang melibatkan penggunaan metode train_step dalam model turunan untuk mengatur pelatihan pada tingkat batch."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
