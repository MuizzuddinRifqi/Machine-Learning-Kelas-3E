{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum 1\n",
    "Klasifikasi üê± dan üê∂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deskripsi\n",
    "Pada praktikum ini kita akan membuat model klasifikasi CNN sederhana pada kasus citra kucing dan anjing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langkah 1 - Import Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengimpor pustaka TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Mengimpor ImageDataGenerator dari Keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langkah 2 - Pra Pengolahan Data\n",
    "Pada tahap ini kita akan sedikit melakukan manipulasi pada citra yang digunakan. Manipulasi yang dilakukan diantaranya adalah normalisasi nilai piksel, koreksi kemiringan, pembesaran (zoom), dan flip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 2.1. Pra Pengolahan Data Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2511 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Membuat objek ImageDataGenerator untuk augmentasi gambar selama pelatihan\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,  # Rescaling gambar ke rentang [0, 1]\n",
    "                                   shear_range=0.2,  # Transformasi cedera (shearing)\n",
    "                                   zoom_range=0.2,   # Transformasi zoom\n",
    "                                   horizontal_flip=True)  # Flip horizontal gambar\n",
    "\n",
    "# Memuat data pelatihan dari direktori 'dataset/training_set' dengan augmentasi\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size=(64, 64),  # Ukuran gambar target\n",
    "                                                 batch_size=32,          # Ukuran batch\n",
    "                                                 class_mode='binary')   # Mode kelas (binary untuk klasifikasi biner)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 2.2. Pra Pengolahan Data Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Membuat objek ImageDataGenerator untuk pengujian data gambar\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescaling gambar ke rentang [0, 1]\n",
    "\n",
    "# Memuat data pengujian dari direktori 'dataset/test_set'\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                           target_size=(64, 64),  # Ukuran gambar target\n",
    "                                           batch_size=32,          # Ukuran batch\n",
    "                                           class_mode='binary')   # Mode kelas (binary untuk klasifikasi biner)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langkah 3 - Pembuatan Model CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.1.  - Inisiasi Model CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat model jaringan saraf konvolusi (CNN) kosong\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.2. - Pembuatan Layer Konvolusi 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan lapisan konvolusi ke dalam model CNN\n",
    "# - filters: Jumlah filter (kernel) yang digunakan\n",
    "# - kernel_size: Ukuran kernel konvolusi (misalnya, 3x3)\n",
    "# - activation: Fungsi aktivasi yang digunakan (dalam kasus ini, ReLU)\n",
    "# - input_shape: Bentuk input gambar (64x64 piksel dengan 3 saluran warna RGB)\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.3 - Pembuatan Layer Pooling 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan lapisan max-pooling ke dalam model CNN\n",
    "# - pool_size: Ukuran jendela max-pooling (misalnya, 2x2)\n",
    "# - strides: Jarak antara langkah-langkah max-pooling (misalnya, 2)\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.4 - Pembuatan Layer Konvolusi 2 dan Pooling 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan lapisan konvolusi ke dalam model CNN\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "\n",
    "# Menambahkan lapisan max-pooling ke dalam model CNN\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.5 - Flattening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan lapisan Flatten ke dalam model CNN\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.6 - Fully Connected Layer 1 (Input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan lapisan fully connected (terhubung penuh) ke dalam model CNN\n",
    "# - units: Jumlah unit atau neuron dalam lapisan\n",
    "# - activation: Fungsi aktivasi yang digunakan (dalam kasus ini, ReLU)\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.7 - Fully Connected Layer 2 (Output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan lapisan fully connected (terhubung penuh) ke dalam model CNN\n",
    "# - units: Jumlah unit atau neuron dalam lapisan (dalam kasus ini, 1)\n",
    "# - activation: Fungsi aktivasi yang digunakan (sigmoid untuk klasifikasi biner)\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.8 - Compile Model CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengkompilasi model CNN\n",
    "# - optimizer: Algoritma optimasi (dalam kasus ini, 'adam' adalah Adam optimizer)\n",
    "# - loss: Fungsi kerugian yang digunakan (dalam kasus ini, 'binary_crossentropy' untuk klasifikasi biner)\n",
    "# - metrics: Metrik evaluasi yang akan dihitung (dalam kasus ini, akurasi)\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penggunaan ***loss function binary crossentropy*** dikarenakan kita hanya melakukan klasifikasi pada dua kelas, yaitu kucing dan anjing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 4 - Fit CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "79/79 [==============================] - 66s 816ms/step - loss: 0.0100 - accuracy: 0.9881 - val_loss: 28.1219 - val_accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 16s 206ms/step - loss: 5.7688e-11 - accuracy: 1.0000 - val_loss: 28.1448 - val_accuracy: 0.5000\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 16s 207ms/step - loss: 6.2166e-11 - accuracy: 1.0000 - val_loss: 28.1448 - val_accuracy: 0.5000\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 17s 218ms/step - loss: 1.4693e-10 - accuracy: 1.0000 - val_loss: 28.1451 - val_accuracy: 0.5000\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 16s 205ms/step - loss: 7.5084e-11 - accuracy: 1.0000 - val_loss: 28.1452 - val_accuracy: 0.5000\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 19s 241ms/step - loss: 3.9195e-10 - accuracy: 1.0000 - val_loss: 28.1460 - val_accuracy: 0.5000\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 19s 235ms/step - loss: 1.7612e-10 - accuracy: 1.0000 - val_loss: 28.1464 - val_accuracy: 0.5000\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 19s 235ms/step - loss: 3.4806e-10 - accuracy: 1.0000 - val_loss: 28.1467 - val_accuracy: 0.5000\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 18s 230ms/step - loss: 7.9961e-11 - accuracy: 1.0000 - val_loss: 28.1477 - val_accuracy: 0.5000\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 18s 228ms/step - loss: 1.1358e-10 - accuracy: 1.0000 - val_loss: 28.1479 - val_accuracy: 0.5000\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 18s 233ms/step - loss: 1.1611e-10 - accuracy: 1.0000 - val_loss: 28.1484 - val_accuracy: 0.5000\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 20s 253ms/step - loss: 3.9765e-10 - accuracy: 1.0000 - val_loss: 28.1499 - val_accuracy: 0.5000\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 18s 231ms/step - loss: 1.8736e-10 - accuracy: 1.0000 - val_loss: 28.1505 - val_accuracy: 0.5000\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 29s 369ms/step - loss: 5.3136e-10 - accuracy: 1.0000 - val_loss: 28.1528 - val_accuracy: 0.5000\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 37s 472ms/step - loss: 4.6248e-10 - accuracy: 1.0000 - val_loss: 28.1548 - val_accuracy: 0.5000\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 2.3813e-10 - accuracy: 1.0000 - val_loss: 28.1555 - val_accuracy: 0.5000\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 6.6361e-11 - accuracy: 1.0000 - val_loss: 28.1563 - val_accuracy: 0.5000\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 31s 398ms/step - loss: 6.9823e-11 - accuracy: 1.0000 - val_loss: 28.1566 - val_accuracy: 0.5000\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 16s 200ms/step - loss: 3.1208e-10 - accuracy: 1.0000 - val_loss: 28.1583 - val_accuracy: 0.5000\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 16s 208ms/step - loss: 1.9465e-10 - accuracy: 1.0000 - val_loss: 28.1594 - val_accuracy: 0.5000\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 16s 203ms/step - loss: 3.3920e-10 - accuracy: 1.0000 - val_loss: 28.1612 - val_accuracy: 0.5000\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 15s 195ms/step - loss: 1.3894e-10 - accuracy: 1.0000 - val_loss: 28.1625 - val_accuracy: 0.5000\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 15s 195ms/step - loss: 6.9884e-11 - accuracy: 1.0000 - val_loss: 28.1629 - val_accuracy: 0.5000\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 15s 189ms/step - loss: 2.0895e-10 - accuracy: 1.0000 - val_loss: 28.1642 - val_accuracy: 0.5000\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 15s 185ms/step - loss: 1.4228e-10 - accuracy: 1.0000 - val_loss: 28.1655 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d309115a90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melatih model CNN\n",
    "# - x: Data pelatihan (dalam hal ini, 'training_set')\n",
    "# - validation_data: Data validasi (dalam hal ini, 'test_set')\n",
    "# - epochs: Jumlah iterasi pelatihan (dalam hal ini, 25)\n",
    "cnn.fit(x=training_set, validation_data=test_set, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 5 - Prediksi dengan 1 Citra\n",
    "Pada langkah ini, kita akan mencoba melakukan prediksi pada 1 citra anjing dan kucing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n"
     ]
    }
   ],
   "source": [
    "# Mengimpor pustaka numpy dan modul image dari Keras\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Memuat gambar pengujian dan menyesuaikannya menjadi ukuran target (64x64 piksel)\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Melakukan prediksi menggunakan model CNN\n",
    "result = cnn.predict(test_image)\n",
    "\n",
    "# Mengambil indeks kelas dari data pelatihan\n",
    "class_indices = training_set.class_indices\n",
    "\n",
    "# Menentukan hasil prediksi berdasarkan hasil dari model\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
