{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "no3RricLUs7a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh0N-ft9VbTC",
        "outputId": "fe6cf0bc-2430-444b-cbad-0a3b27783fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 1s 1us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka-tZuguVjcw",
        "outputId": "21a0d4a7-3d36-49d0-ece3-c6695dd16f54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Membuka dan membaca file yang ditentukan.\n",
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1G12gjqVpH7",
        "outputId": "7fa22cd8-8764-4ba0-c89e-e6456ca9728f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpx3yqk5Vt0A",
        "outputId": "db9e1296-6fad-4d3e-cc50-4e4424d516ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# Menghitung dan mencetak jumlah karakter unik dalam teks.\n",
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6YP2dMuV9SW",
        "outputId": "450ef381-2745-411b-9f9c-c14c959f15f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars # Menghasilkan output dari operasi sebelumnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OOujZghgWJTP"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan lapisan StringLookup.\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwx3bVEBXKeY",
        "outputId": "b4c857c9-b847-4b3c-a884-b57ce6d844c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengonversi karakter-karakter Unicode menjadi ID numerik.\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AfM1vBwoXRjS"
      },
      "outputs": [],
      "source": [
        "# Membuat lapisan StringLookup baru.\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRQKV2UfXWWZ",
        "outputId": "8b4dbee7-39c4-4455-9649-a1c86661e006"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBB2vgbrXcLm",
        "outputId": "779d0a70-764c-435a-c1d4-1eaef53ccb0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy() # Menggabungkan karakter-karakter Unicode dalam chars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "za7R4HKuXguy"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1) # Mengonversi ID numerik kembali menjadi karakter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLNuzQXkXsFj",
        "outputId": "44a7c869-507b-4e02-ddf0-82b75d62ab3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ambil tensor yang berisi kode unicode untuk bagi string 'text' jadi unicode.\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ogfNgQR7X036"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids) # Buat dataset dari all_ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3eva0kUX56Z",
        "outputId": "ec661b47-068f-4e21-adca-b2bf39ba88de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10): # loop untuk ambil 10 elemen pertama dataset ids_dataset.\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8')) # Ambil elemen ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lU9u-xv4YBpE"
      },
      "outputs": [],
      "source": [
        "seq_length = 100 # Jumlah sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4r6v2UXYFnV",
        "outputId": "b0dd5d24-6271-4184-f951-e3fe1d699da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True) # Jika panjang ID tidak habis dibagi oleh seq_length + 1, maka elemen yang tersisa akan dihapus.\n",
        "\n",
        "for seq in sequences.take(1): # Ambil satu sekuenes /batch.\n",
        "  print(chars_from_ids(seq)) # Cetak karakter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zj7TeODYKVZ",
        "outputId": "26f00aa3-f110-48bc-9f6b-c06e4e60871c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5): # Ambil 5 sekuens pertama.\n",
        "  print(text_from_ids(seq).numpy()) # Cetak teks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Zcj1PkDUYWOY"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1] # Ambil semua elemen kecuali elemen terakhir dai sekuens.\n",
        "  target_text = sequence[1:] # Ambil semua elmeen kecuali elemen pertama dari sekuens.\n",
        "  return input_text, target_text # Mengembalikan nilai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1svyL5NpYjoI",
        "outputId": "3019c80f-f1ed-4413-9853-9d0dbbb749c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\")) # Bagi sequence jadi 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "14aW8tK9YwQh"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target) # Mapping sekuens dalam dataset ke pasangan input dan target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbZXF6d4Y2sV",
        "outputId": "eacc6067-d8e1-4f4e-e952-8140cdaafeee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy()) # Cetak label input.\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy()) # Cetak label target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JuwjcamZGRY",
        "outputId": "d63f2dbc-c4dd-4249-8c5e-3e0e8918b38c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE) # Acak elemen.\n",
        "    .batch(BATCH_SIZE, drop_remainder=True) # Mengelompokkan elemen dataset menjadi batch.\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)) # Mengoptimalkan proses memuat data.\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5RXnZLYDZK1z"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256 # Jumlah embedding untuk represntasi vektor karakter.\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024 # Jumlah unit dalam RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pEbHGOoWZTdu"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states # Mengembalikan urutan karakter yang diprediksi serta status terakhir RNN.\n",
        "    else:\n",
        "      return x # Hanya akan mengembalikan urutan karakter yang diprediksi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Cwl81bBRZYOS"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size, # Menentukan seberapa banyak karakter yang ada dalam vokabulari yang digunakan oleh model.\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3Isa4lKZcy5",
        "outputId": "b225c1b4-8676-491e-f379-d935344996df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch) # Membuat prediksi dengan memberikan input_example_batch sebagai input.\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB9HSLL8Zm-U",
        "outputId": "09226d46-02e2-4251-e4be-220b83fb6d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary() # Cetak ringkasan (summary) dari model TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5DbR5mTCZqDO"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy() # Menghapus dimensi tambahan dan menghasilkan tensor satu dimensi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBQkAzSUZ1A5",
        "outputId": "9faae091-a7e9-4b65-cdef-c25337b98064"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([40, 41, 54, 18, 58, 65, 24, 43, 59, 14, 37, 63,  2,  8, 54, 41, 34,\n",
              "       56, 33, 33, 37, 33, 40, 10, 31, 56, 40,  8, 62, 24, 58, 65, 51, 57,\n",
              "       57, 54, 40, 56, 31,  3,  4, 46, 57, 24,  5, 33, 59, 42, 60, 41, 30,\n",
              "       27,  0, 51, 31, 37, 23, 36, 30, 38,  6, 11, 15,  7, 41, 25, 33,  0,\n",
              "       43,  8, 54, 61,  8, 12,  0, 24, 37, 14,  2, 27, 63, 46,  6, 38, 19,\n",
              "       14, 14, 34,  7,  6, 60, 37, 24, 55,  8, 39, 20, 47, 12, 36])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices # Indeks karakter yang diambil secara acak dari prediksi model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSr5ZKDhZ4G1",
        "outputId": "f244202e-57af-4e04-8be2-bc772906759a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b\"eping, weeping and blubbering.\\nStand up, stand up; stand, and you be a man:\\nFor Juliet's sake, for h\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"aboEszKdtAXx -obUqTTXTa3Rqa-wKszlrroaqR!$grK&TtcubQN[UNK]lRXJWQY':B,bLT[UNK]d-ov-;[UNK]KXA Nxg'YFAAU,'uXKp-ZGh;W\"\n"
          ]
        }
      ],
      "source": [
        "# Mencetak teks dari input dan prediksi karakter selanjutnya dari model.\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UUQODRQWaFpW"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True) # Menginisialisasi fungsi kerugian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98HuIhEtaJWr",
        "outputId": "2c0d5209-86b4-4072-830f-847e52bb1bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1897993, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Menghitung dan mencetak informasi tentang hasil prediksi dan kerugian.\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M79dW1aZaRtG",
        "outputId": "ea4614dc-e367-4a1a-8b6c-a3ec3ca93c99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.009544"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy() # Menghasilkan nilai eksponensial dari example_batch_mean_loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "A8ECiqfLaV82"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss) # Mengatur pengaturan pelatihan untuk model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0AKU1W0QaeUG"
      },
      "outputs": [],
      "source": [
        "# Menentukan cara untuk menyimpan checkpoint selama pelatihan model.\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sXcMerX8ao97"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg_kaeRcatLJ",
        "outputId": "00c83991-13a8-4c17-e65b-be34e7387cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 1000s 6s/step - loss: 2.7432\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 999s 6s/step - loss: 2.0058\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 1002s 6s/step - loss: 1.7205\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 998s 6s/step - loss: 1.5557\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 999s 6s/step - loss: 1.4557\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 1021s 6s/step - loss: 1.3864\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 1012s 6s/step - loss: 1.3335\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 1010s 6s/step - loss: 1.2896\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 1006s 6s/step - loss: 1.2486\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 1004s 6s/step - loss: 1.2096\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 1002s 6s/step - loss: 1.1712\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 1001s 6s/step - loss: 1.1308\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 1012s 6s/step - loss: 1.0885\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 1006s 6s/step - loss: 1.0440\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 996s 6s/step - loss: 0.9965\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 1005s 6s/step - loss: 0.9466\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 1002s 6s/step - loss: 0.8948\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 994s 6s/step - loss: 0.8432\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 994s 6s/step - loss: 0.7902\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 997s 6s/step - loss: 0.7425\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback]) # Melatih model menggunakan data dari dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "g6l7p0D-uarh"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9CJjrzQjufk9"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeHA75pTu5ge",
        "outputId": "5f8c5e42-f86d-4578-b85a-cdce75861d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "You say, he says he indeed.\n",
            "\n",
            "LORD WILLOUGHBY:\n",
            "Bareless, my great boy.\n",
            "\n",
            "Provost:\n",
            "As 'twere a son of King of Elyer's life.\n",
            "What shall scarce be so so budded in your bed\n",
            "And swell proclaim our Romeo calm,\n",
            "Could not less furtle villain: let me hear from help.\n",
            "\n",
            "KING HENRY VI:\n",
            "My Lord of Warwick, hear me breaking me married\n",
            "Jaggage-men, to dance his leap: you make him wink\n",
            "Help not all framed away their fines. Putticotion may soon\n",
            "Rest; these nothing blest musicians endem:\n",
            "If I thought made Glunterence of the nurse,\n",
            "Not set up all then. Your from his baggacies\n",
            "He could draw it in the witness of his\n",
            "mistress'd Paulina.\n",
            "Ancies spriad of a king, great king, we fear\n",
            "There is a fire show'd upon me.\n",
            "\n",
            "Third Watchman:\n",
            "A marb, stone, of whom defend a word-well incring\n",
            "As else proud and these fat as civelity,\n",
            "I mean to blass along where you'll strive, let\n",
            "To chase your only long battle; if I\n",
            "Hold in post, and are consented\n",
            "He was a penural delighters,\n",
            "Which plotted most growing thus have great,\n",
            "And t \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.702383518218994\n"
          ]
        }
      ],
      "source": [
        "# Menghasilkan teks berkelanjutan berdasarkan teks awal \"ROMEO:\".\n",
        "start = time.time() # Memulai penghitungan waktu.\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "# Loop sebanyak 1000 kali.\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "# Cetak bersama dengan waktu yang diperlukan.\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yULIwwCcvCLq",
        "outputId": "c5e9a194-3f37-4bdc-f37a-975ce1600fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nCanst thou yet?\\n\\nClown:\\nCousin, I pardon him, as we, as bright-late\\nCarble all your enemies, lives, to art,\\nWho from pay thee from thy face the joy may\\nplease you, lets' cut off blush and blunt,\\nIf ever yet let me be vail'd before to be\\nbrief; we sathon dischined at barbard he of while.\\n\\nDUKE OF YORK:\\nShe may do mine sorrow, think ut you may stay.\\n\\nHENRY BOLINGBROKE:\\nYou shames nothing but shortly for it, it is no daughter.\\nGood paint before thy way so well as I do,--\\nIf you have set a woman and amends;\\nUncle, Signior Gremio, how farewell gown.\\nMy fair Bohemia, how fon your grace I meant,\\nMy sovereign royal marge my sons, we\\nchose this crown and cover.\\nCome on, by Gaint.\\n\\nEDBAL:\\nAlack, protector: I have from your voices and\\nThe villain's soothing news indirmponisgman:\\nYour brother Richard, noing of this face\\nWhere you should not believe I since you do excuse my head\\nAnd prone with the remembrance of a great divinu.\\nWell met, for I intend so much writ in your own,\\nAnother lies, which s\"\n",
            " b\"ROMEO:\\nWhy, she's here! I hope so, be\\nlooking with two sufferately.\\n\\nSIRINBURY:\\nIt is a rap, and aid, how help hook! Het hath a\\ngraved in fair Marcius.\\n\\nALONSO:\\nWhat, hear me, fair suspicion;\\nAnd were I seek of mine, that they do thou\\nThe instant and widow, by men's garden!\\n\\nEDWARD:\\nI will, my mystery govern well enjoin'd.\\n\\nISABELLA:\\nToo monalughter\\nWhose consolverts that are most welcome.\\n\\nFirst Watchman:\\nAy, milthon, fair son.\\n\\nDUCHESS OF YORK:\\nWould they were banish'd to her heart bleeding in\\nbeing stars doubled, hath sent your towns and married when\\nThou flow'st, the vile rabbed shed with me alive.\\n\\nDUKE VINCENTIO:\\nOf gove way nor from him, being but a fool\\nTo seek to an unusualage, make does my fortune.\\n\\nKING HENRY VI:\\nFet it do you ever return to bed,\\nAnd shall you not have married my foes.\\n\\nGLOUCESTER:\\n\\nKING EDWARD IV:\\nMarch, we are not, sir, that you do name a child,\\nOr every man that sees report; and visit them\\nIn bootless officer of dishouses,\\nWhen you have not saints him, where yo\"\n",
            " b\"ROMEO:\\nPlass for the contrace\\nWhy then 't, slow in partial vault;\\nFor so your first are slain, to make for your temples of\\nmine eye. Caie commend to drink him that will sit for the\\nlove: I have forgot'd your cousin's death, lest at Northampitain;\\nthey may come hitherwage, the better, then 'mark me; and supply,\\nFor little of by his mouth, unfill'd this bed.\\n\\nNurse:\\nNo matter; call; I am now sometime born breath.\\nO sirrah, mothersoo, royal sir,\\nAnd see's my man: paison! shall we perceive\\nHe came diddesty strike.\\n\\nKING EDWARD IV:\\nNo, madam, we may learn upon you!\\n\\nCORIOLANUS:\\nLet them past curbfis veil.\\n\\nCURTIS:\\nCome, you are marcius;' and shall think of you.\\nCome, gentle Margaret, and say I knew the world,\\nOr never fall. I not win once come of him\\nbefore my: as me for a very morning's ground.\\n\\nPRINCE EDWARD:\\nMarry, I find me to me; for now he lives.\\n\\nTEBBSTY:\\nMy lord?\\n\\nKING RICHARD III:\\nWell, I come for our process\\nOf smulls after a goodly lempet: it\\nis in Clarence to his majesty.\\nMy gracious \"\n",
            " b\"ROMEO:\\nHow now, fair good and fly! fair, most loat?\\n\\nJOHN O EDWARD:\\nBut I'll say an erran that I am lost.\\n\\nKATHARINA:\\nIf thou art watch'd for her sweet uncles;\\nHelp her a-gentle. What, o' God's name, I\\ncannot, Lady Bannarf'd, the company physics hold\\nOn my order: do him back\\nUnsuil by me; as I am soon to seek a child.\\nTorry thou art acquittance fetch his body\\nThat she will not for myself.\\n\\nLUCIO:\\n\\nISABELLA:\\nMy us, it will,\\nAnd Salamy with his gorge! our subject, make thee tare\\nTo part their royal brother Claudio.\\n\\nISABELLA:\\nPlease your honour.\\n\\nBoatswain:\\nIf I do sole me again. What are you, sir?\\n\\nELBOW:\\nMarry, sir, I think 'twas broke their fellows: though thou wert so open,\\nWhen, as be bold, helping him to write;\\nIf thou in charges not upon Summon things,\\nNor tongues convenient boas them all service.\\n\\nDUKE OF AUMERLE:\\nPerrusted and Margaret, Trybul, I hadard, harde:\\nHe hath not so do proud me to the sun,\\nAnd he his father's odds a word or two\\nour varis. Let within me: but I am sent\\nBefore \"\n",
            " b\"ROMEO:\\nWhat are you, sir? do, she was a put me news.\\n\\nGentlewEr:\\nAy, by any weep, that wouldst tide this dice op bold,\\nAnd I am peedly; believe me, some peace with\\nsmalts, as becomisiby; my trouble is here.\\n\\nKING EDWARD IV:\\nCall Calais with you.\\n\\nSOMERSET:\\nA very little queen. I am past our poyor?\\nIf I do suitor live.\\n\\nISABELLA:\\nI am a goodly day,\\nCan I do so, then send it, servile the majesty,\\nTo death us well. What, is he were forbided\\nBy fill'd law and empty im gry token,\\nWhereof we made what's here proclaim'd axfide;\\nYet he falls old 'twas for thy foul two back\\nTo the dead temper'd public damn'd withal.\\nAnd let Romeo hold me many thouson\\nOur form and violent for hour censure,\\nEivility, like sides along in thee.\\n\\nDUKE OF AUMERLE:\\nIndeed, I see, as gentle Norfolk and mine,\\nThat ancienly remembrance was thy bed,\\nAnd so prosper 'twas revortion:\\nI mar, along with this foot upon this election.\\n\\nGRUMIO:\\nI gave you, sir: I will do so;\\nFaith, and well, what are thy news? and\\nRivers, VOundame; com\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.528480768203735\n"
          ]
        }
      ],
      "source": [
        "# Menghasilkan teks berkelanjutan berdasarkan teks awal yang telah ditentukan.\n",
        "start = time.time() # Memulai penghitungan waktu.\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "# Loop sebanyak 1000 kali.\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "# Cetak bersama dengan waktu yang diperlukan.\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItJNUhAhvJJr",
        "outputId": "072ea7a7-b4f9-4a16-89cd-e576e44b8bbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7eefce331060>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "# Menyimpan model one_step_model ke dalam format saved model.\n",
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASP7j5jJvOOd",
        "outputId": "a4136dc7-d5e2-426d-d6da-712b9b45d8c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "His name is Came, 'Citizens! make all medly player\n",
            "To your succersise whence thou office; off but n\n"
          ]
        }
      ],
      "source": [
        "# Menggunakan model yang telah dilatih untuk menghasilkan teks berkelanjutan.\n",
        "states = None # Menyimpan keadaan internal dari model.\n",
        "next_char = tf.constant(['ROMEO:']) # Teks awal untuk menghasilkan teks berikutnya.\n",
        "result = [next_char]\n",
        "\n",
        "# Loop sebanyak 100 kali.\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\")) # Cetak hasil akhir teks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KACvqUnS9-eE"
      },
      "source": [
        "**Tugas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "wDB2wqrz-BT9"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "YJahZgIzjeo-"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "OvUoR9LkjpPC"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL2g27sfjuCs",
        "outputId": "1ae849b6-6286-4c1c-b7c0-99f06c927cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 1030s 6s/step - loss: 2.7058\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eefc7f8bac0>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48hPTKKXnvBS",
        "outputId": "760fffd9-4c6c-4e9e-b50a-f78f379950b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1959\n",
            "Epoch 1 Batch 50 Loss 2.0346\n",
            "Epoch 1 Batch 100 Loss 1.9226\n",
            "Epoch 1 Batch 150 Loss 1.8578\n",
            "Epoch 2 Batch 0 Loss 1.7885\n",
            "Epoch 2 Batch 50 Loss 1.7323\n",
            "Epoch 2 Batch 100 Loss 1.6744\n",
            "Epoch 2 Batch 150 Loss 1.6434\n",
            "Epoch 3 Batch 0 Loss 1.5567\n",
            "Epoch 3 Batch 50 Loss 1.5859\n",
            "Epoch 3 Batch 100 Loss 1.6036\n",
            "Epoch 3 Batch 150 Loss 1.4830\n",
            "Epoch 4 Batch 0 Loss 1.4267\n",
            "Epoch 4 Batch 50 Loss 1.3942\n",
            "Epoch 4 Batch 100 Loss 1.4475\n",
            "Epoch 4 Batch 150 Loss 1.4286\n",
            "Epoch 5 Batch 0 Loss 1.3921\n",
            "\n",
            "Epoch 5 Loss: 1.3921\n",
            "Time taken for 1 epoch 9.00 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 50 Loss 1.3536\n",
            "\n",
            "Epoch 5 Loss: 1.3842\n",
            "Time taken for 1 epoch 297.73 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 100 Loss 1.4340\n",
            "\n",
            "Epoch 5 Loss: 1.3819\n",
            "Time taken for 1 epoch 587.35 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 150 Loss 1.3628\n",
            "\n",
            "Epoch 5 Loss: 1.3802\n",
            "Time taken for 1 epoch 878.69 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3491\n",
            "Epoch 6 Batch 50 Loss 1.3512\n",
            "Epoch 6 Batch 100 Loss 1.3657\n",
            "Epoch 6 Batch 150 Loss 1.3164\n",
            "Epoch 7 Batch 0 Loss 1.2615\n",
            "Epoch 7 Batch 50 Loss 1.2568\n",
            "Epoch 7 Batch 100 Loss 1.2925\n",
            "Epoch 7 Batch 150 Loss 1.2987\n",
            "Epoch 8 Batch 0 Loss 1.2177\n",
            "Epoch 8 Batch 50 Loss 1.2654\n",
            "Epoch 8 Batch 100 Loss 1.2471\n",
            "Epoch 8 Batch 150 Loss 1.2480\n",
            "Epoch 9 Batch 0 Loss 1.1823\n",
            "Epoch 9 Batch 50 Loss 1.1923\n",
            "Epoch 9 Batch 100 Loss 1.1987\n",
            "Epoch 9 Batch 150 Loss 1.2481\n",
            "Epoch 10 Batch 0 Loss 1.1307\n",
            "\n",
            "Epoch 10 Loss: 1.1307\n",
            "Time taken for 1 epoch 7.43 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 50 Loss 1.1654\n",
            "\n",
            "Epoch 10 Loss: 1.1490\n",
            "Time taken for 1 epoch 297.77 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 100 Loss 1.1589\n",
            "\n",
            "Epoch 10 Loss: 1.1559\n",
            "Time taken for 1 epoch 591.28 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 150 Loss 1.2102\n",
            "\n",
            "Epoch 10 Loss: 1.1597\n",
            "Time taken for 1 epoch 883.50 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  mean.reset_states()\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    logs = model.train_step([inp, target])\n",
        "    mean.update_state(logs['loss'])\n",
        "\n",
        "    if batch_n % 50 == 0:\n",
        "      template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "      print(template)\n",
        "\n",
        "      # saving (checkpoint) the model every 5 epochs\n",
        "      if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "        print()\n",
        "        print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "        print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "        print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Pada praktikum 2 menggunakan Model Fit sedangkan pada kode diatas menggunakan Model Teacher-Forcing dimana model ini merupakan pendekatan pelatihan yang melibatkan pemberian jawaban yang benar sebagai input selama proses pelatihan. Ini lebih spesifik terkait dengan cara pelatihan model untuk tugas tertentu, seperti generasi urutan."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
